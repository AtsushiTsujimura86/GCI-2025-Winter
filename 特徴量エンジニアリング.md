# 🧰 特徴量エンジニアリングまとめ

## 1. 数値変数の変換
- 多くのモデルは「特徴量が正規分布に近いほど学習しやすい」。

### 標準化・正規化
- **標準化**：平均0、分散1  
- **正規化**：0〜1 にスケール

### 非線形変換
- 対数変換、平方根変換、Box-Cox など  
- 分布の歪みを補正する目的

### 交差項（Interaction）
- 例：`FeatureA × FeatureB`  
- 特徴量同士の相互作用を表現

---

## 2. カテゴリカル変数の変換

### ラベルエンコーディング
- 単純に数字へ置き換える（手軽）

### カウントエンコーディング
- 各カテゴリの出現回数で置き換える

### ラベルカウントエンコーディング
- ラベル情報＋頻度を組み合わせた方式

### One-Hot Encoding（OHE）
- カテゴリを 0/1 のベクトル化  
- **線形モデルとの相性が最強**  
- 決定木系では不要なことも多い

### ターゲットエンコーディング
- そのカテゴリの目的変数平均値で置換  
- 過学習に注意（CV必須）

---

## 3. 時系列データの扱い

### 比率特徴量
- 例：当月売上 / 前月売上（増減率）

### 移動平均
- 3時間ごとの平均など

### 周期性の表現
- 曜日、月、時間帯を特徴量化
- 円で表して三角関数を使う

---

## 4. 特徴選択

### RFE（再帰的特徴量削除）
- 重要度の低い特徴を段階的に削除  
- 特徴量同士が影響し合う前提で選択可能
